{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the UNet model\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(64, out_channels, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()  # Apply sigmoid to output probabilities\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Dataset class to load images and masks\n",
    "class GlacierDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.mask_files = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Pad image and mask to make dimensions divisible by 32\n",
    "        image = pad_to_nearest_32(image)\n",
    "        mask = pad_to_nearest_32(mask)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        \n",
    "        # Ensure the mask has the correct dimensions by adding a channel dimension\n",
    "        mask = np.expand_dims(mask, axis=0)  # Add the channel dimension\n",
    "        mask = torch.tensor(mask, dtype=torch.float32)  # Convert to tensor\n",
    "        mask = mask / 255.0  # Ensure mask values are between 0 and 1 for sigmoid activation\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "# Padding function to make the image dimensions a multiple of 32\n",
    "def pad_to_nearest_32(image):\n",
    "    h, w = image.shape[:2]\n",
    "    pad_h = (32 - h % 32) % 32\n",
    "    pad_w = (32 - w % 32) % 32\n",
    "    padded_image = cv2.copyMakeBorder(image, 0, pad_h, 0, pad_w, cv2.BORDER_CONSTANT, value=0)\n",
    "    return padded_image\n",
    "\n",
    "# Train model function\n",
    "def train_model(model, train_loader, device, num_epochs, lr):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, masks in train_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Ensure outputs and masks are of the same size\n",
    "            if outputs.size(2) != masks.size(2) or outputs.size(3) != masks.size(3):\n",
    "                outputs = torch.nn.functional.interpolate(outputs, size=masks.shape[2:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "            # Loss calculation\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "# Prediction Function\n",
    "def predict_mask(image_path, model, device):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        mask = torch.sigmoid(output).squeeze(0).cpu().numpy()\n",
    "        mask = (mask > 0.5).astype(np.uint8)\n",
    "    return mask[0]  # Assuming binary segmentation\n",
    "\n",
    "# Post-processing techniques\n",
    "def morphological_operations(mask):\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask_opened = cv2.morphologyEx(mask_closed, cv2.MORPH_OPEN, kernel)\n",
    "    return mask_opened\n",
    "\n",
    "# Noise reduction using Gaussian blur\n",
    "def reduce_noise(mask):\n",
    "    return cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "\n",
    "# Edge refinement using Canny edge detection\n",
    "def refine_boundaries(mask):\n",
    "    return cv2.Canny(mask, threshold1=100, threshold2=200)\n",
    "\n",
    "def post_process_mask(mask):\n",
    "    # Ensure the mask is 2D grayscale before processing\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(\"The mask should be a 2D image\")\n",
    "    \n",
    "    mask = morphological_operations(mask)\n",
    "    mask = reduce_noise(mask)\n",
    "    mask = refine_boundaries(mask)\n",
    "    return mask\n",
    "\n",
    "# Difference Mapping\n",
    "def calculate_difference(before_mask, after_mask):\n",
    "    # Calculate the difference between the before and after masks\n",
    "    difference_mask = np.abs(before_mask - after_mask)\n",
    "    \n",
    "    # Optional: Use morphological operations to clean the difference map\n",
    "    difference_mask = morphological_operations(difference_mask)\n",
    "    \n",
    "    return difference_mask\n",
    "\n",
    "# Area Calculation\n",
    "def calculate_area(mask):\n",
    "    # Calculate the area of the segmented region\n",
    "    return np.sum(mask)  # This will count the number of non-zero pixels (i.e., segmented area)\n",
    "\n",
    "# Visualizing Results\n",
    "# Visualize overlays\n",
    "def overlay_mask(image_path, mask, color=\"red\"):\n",
    "    image = cv2.imread(image_path)\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Resize mask to match image dimensions\n",
    "    mask_resized = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Create a colored mask\n",
    "    mask_colored = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    if color == \"red\":\n",
    "        mask_colored[..., 2] = mask_resized * 255  # Red channel\n",
    "    elif color == \"green\":\n",
    "        mask_colored[..., 1] = mask_resized * 255  # Green channel\n",
    "    elif color == \"blue\":\n",
    "        mask_colored[..., 0] = mask_resized * 255  # Blue channel\n",
    "\n",
    "    # Overlay the mask on the image\n",
    "    overlayed_image = cv2.addWeighted(image, 1.0, mask_colored, 0.5, 0)\n",
    "    \n",
    "    return overlayed_image\n",
    "\n",
    "# Visualization function\n",
    "def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "    before_mask = predict_mask(before_image_path, model, device)\n",
    "    after_mask = predict_mask(after_image_path, model, device)\n",
    "\n",
    "    before_mask = post_process_mask(before_mask)\n",
    "    after_mask = post_process_mask(after_mask)\n",
    "\n",
    "    difference_mask = calculate_difference(before_mask, after_mask)\n",
    "\n",
    "    before_area = calculate_area(before_mask)\n",
    "    after_area = calculate_area(after_mask)\n",
    "    difference_area = calculate_area(difference_mask)\n",
    "\n",
    "    print(f\"Area of before mask: {before_area} pixels\")\n",
    "    print(f\"Area of after mask: {after_area} pixels\")\n",
    "    print(f\"Area of difference: {difference_area} pixels\")\n",
    "\n",
    "    before_overlay = overlay_mask(before_image_path, before_mask, color=\"red\")\n",
    "    after_overlay = overlay_mask(after_image_path, after_mask, color=\"red\")\n",
    "    difference_overlay = overlay_mask(before_image_path, difference_mask, color=\"green\")\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(before_overlay)\n",
    "    plt.title(\"Before Mask Overlay\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(after_overlay)\n",
    "    plt.title(\"After Mask Overlay\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(difference_overlay)\n",
    "    plt.title(\"Difference Overlay\")\n",
    "    plt.show()\n",
    "\n",
    "# Example paths\n",
    "train_image_dir = \"data/images\"\n",
    "train_mask_dir = \"data/masks\"\n",
    "\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "train_dataset = GlacierDataset(train_image_dir, train_mask_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = UNet(3, 1).to(device)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, device, num_epochs=10, lr=1e-3)\n",
    "\n",
    "# Test prediction and visualization\n",
    "before_image = \"before.png\"\n",
    "after_image = \"after.png\"\n",
    "visualize_and_calculate(before_image, after_image, model, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
