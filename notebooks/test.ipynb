{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 103/103 [00:32<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.4883266683414723\n",
      "Before Mask Shape: (1, 1490, 1016)\n",
      "After Mask Shape: (1, 1492, 1008)\n",
      "Resizing both masks to match the shape of the before_mask: (1, 1490, 1016)\n",
      "Error resizing after_mask: OpenCV(4.10.0) /Users/runner/miniforge3/conda-bld/libopencv_1727648921144/work/modules/imgproc/src/resize.cpp:3789: error: (-215:Assertion failed) !dsize.empty() in function 'resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# U-Net model definition\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
    "        self.encoder2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.encoder3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.encoder4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)  # Up-conv for decoder\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)  # Up-conv for decoder\n",
    "        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)   # Up-conv for decoder\n",
    "        self.upconv1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)    # Up-conv for decoder\n",
    "\n",
    "        # Additional convolutional layers after concatenation to reduce channel sizes\n",
    "        self.conv4 = nn.Conv2d(768, 256, kernel_size=3, padding=1)  # After upconv4\n",
    "        self.conv3 = nn.Conv2d(384, 128, kernel_size=3, padding=1)  # After upconv3\n",
    "        self.conv2 = nn.Conv2d(192, 64, kernel_size=3, padding=1)   # After upconv2\n",
    "        self.conv1 = nn.Conv2d(128, 64, kernel_size=3, padding=1)   # After upconv1\n",
    "\n",
    "        # Final layer\n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool(enc1))\n",
    "        enc3 = self.encoder3(self.pool(enc2))\n",
    "        enc4 = self.encoder4(self.pool(enc3))\n",
    "        \n",
    "        # Bottleneck (no pooling)\n",
    "        mid = self.pool(enc4)\n",
    "\n",
    "        # Decoder path (upsampling and concatenation)\n",
    "        dec4 = self.upconv4(mid)\n",
    "        dec4_resized = F.interpolate(dec4, size=enc4.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec4 = torch.cat([dec4_resized, enc4], dim=1)\n",
    "        #dec4 = torch.cat([dec4, enc4], dim=1)  # Concatenate encoder and decoder\n",
    "        dec4 = self.conv4(dec4)  # Reduce channels after concatenation\n",
    "\n",
    "\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3_resized = F.interpolate(dec3, size=enc3.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec3 = torch.cat([dec3_resized, enc3], dim=1)\n",
    "        #dec3 = torch.cat([dec3, enc3], dim=1)  # Concatenate encoder and decoder\n",
    "        dec3 = self.conv3(dec3)  # Reduce channels after concatenation\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2_resized = F.interpolate(dec2, size=enc2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        dec2 = torch.cat([dec2_resized, enc2], dim=1)\n",
    "        #dec2 = torch.cat([dec2, enc2], dim=1)  # Concatenate encoder and decoder\n",
    "        dec2 = self.conv2(dec2)  # Reduce channels after concatenation\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat([dec1, enc1], dim=1)  # Concatenate encoder and decoder\n",
    "        dec1 = self.conv1(dec1)  # Reduce channels after concatenation\n",
    "\n",
    "        # Final output\n",
    "        return self.final(dec1)\n",
    "\n",
    "# Custom dataset class\n",
    "class GlacierDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(os.listdir(images_dir))\n",
    "        self.mask_paths = sorted(os.listdir(masks_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.images_dir, self.image_paths[idx]))\n",
    "        mask = Image.open(os.path.join(self.masks_dir, self.mask_paths[idx]))\n",
    "\n",
    "        # Convert to grayscale for segmentation (single channel)\n",
    "        mask = mask.convert('L')  # Convert the mask to grayscale (1 channel)\n",
    "        \n",
    "        # Apply transformation if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        # Ensure the mask has the correct shape [1, height, width]\n",
    "        mask = mask.unsqueeze(0)  # Add a channel dimension: [1, height, width]\n",
    "\n",
    "        # Squeeze out any extra dimensions (if they exist)\n",
    "        mask = mask.squeeze(0)  # This will remove any unnecessary dimensions\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "# Helper function to calculate IOU\n",
    "# def calculate_iou(pred_mask, true_mask):\n",
    "#     # Resize pred_mask to match true_mask shape\n",
    "#     pred_mask_resized = np.resize(pred_mask, true_mask.shape)\n",
    "#     #pred_mask_resized = cv2.resize(pred_mask, (true_mask.shape[2], true_mask.shape[1]))\n",
    "\n",
    "#     if pred_mask.shape[1] < true_mask.shape[1]:\n",
    "#         pad_height = true_mask.shape[1] - pred_mask.shape[1]\n",
    "#         pred_mask = np.pad(pred_mask, ((0, 0), (0, pad_height), (0, 0)), mode='constant', constant_values=0)\n",
    "\n",
    "#     if pred_mask.shape[2] < true_mask.shape[2]:\n",
    "#         pad_width = true_mask.shape[2] - pred_mask.shape[2]\n",
    "#         pred_mask = np.pad(pred_mask, ((0, 0), (0, 0), (0, pad_width)), mode='constant', constant_values=0)\n",
    "\n",
    "#     intersection = np.logical_and(pred_mask, true_mask)\n",
    "#     union = np.logical_or(pred_mask, true_mask)\n",
    "#     return np.sum(intersection) / np.sum(union)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def calculate_iou(pred_mask, true_mask):\n",
    "#     # Resize pred_mask to match true_mask shape using OpenCV resize (bilinear interpolation)\n",
    "#     pred_mask_resized = cv2.resize(pred_mask[0], (true_mask.shape[2], true_mask.shape[1]), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "#     # Ensure the pred_mask is a binary mask (0 or 1)\n",
    "#     pred_mask_resized = (pred_mask_resized > 0.5).astype(np.uint8)\n",
    "    \n",
    "#     # Perform logical operations\n",
    "#     intersection = np.logical_and(pred_mask_resized, true_mask[0])  # Assumes both are 3D (batch, height, width)\n",
    "#     union = np.logical_or(pred_mask_resized, true_mask[0])\n",
    "    \n",
    "#     # Calculate IoU\n",
    "#     iou = np.sum(intersection) / np.sum(union)\n",
    "#     return iou\n",
    "\n",
    "\n",
    "def calculate_iou(pred_mask, true_mask):\n",
    "    # Ensure both masks are binary\n",
    "    pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
    "    true_mask = (true_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Resize pred_mask to match true_mask shape (height, width)\n",
    "    pred_mask_resized = cv2.resize(pred_mask, (true_mask.shape[1], true_mask.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Compute Intersection and Union\n",
    "    intersection = np.logical_and(pred_mask_resized, true_mask)\n",
    "    union = np.logical_or(pred_mask_resized, true_mask)\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "    return iou\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, device, num_epochs=2, lr=0.001):\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Binary cross entropy loss for segmentation\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, masks in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            # Ensure masks have the correct shape [batch_size, 1, height, width]\n",
    "            masks = masks.unsqueeze(1)  # Ensure mask has 1 channel\n",
    "            if masks.dim() > 4:\n",
    "                masks = masks.squeeze(1)  # Remove extra dimensions if any\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks.float())  # Ensure mask is float\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "\n",
    "# Visualization and Calculation Function\n",
    "# def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "#     before_image = Image.open(before_image_path)\n",
    "#     after_image = Image.open(after_image_path)\n",
    "\n",
    "#     # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "#     before_image = before_image.convert('RGB')\n",
    "#     after_image = after_image.convert('RGB')\n",
    "\n",
    "#     # Preprocessing and transforming images to tensor\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "#     after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Forward pass for before and after images\n",
    "#         before_output = model(before_image)\n",
    "#         after_output = model(after_image)\n",
    "        \n",
    "#         before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "#         after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "#         before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "#         after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "#         # Calculate IOU\n",
    "#         iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "#         print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "#         # Visualize before and after masks\n",
    "#         fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "#         ax[0].imshow(before_mask, cmap='gray')\n",
    "#         ax[0].set_title(\"Before Mask\")\n",
    "#         ax[1].imshow(after_mask, cmap='gray')\n",
    "#         ax[1].set_title(\"After Mask\")\n",
    "#         ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "#         ax[2].set_title(\"Change Mask\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "# def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "#     before_image = Image.open(before_image_path)\n",
    "#     after_image = Image.open(after_image_path)\n",
    "\n",
    "#     # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "#     before_image = before_image.convert('RGB')\n",
    "#     after_image = after_image.convert('RGB')\n",
    "\n",
    "#     # Preprocessing and transforming images to tensor\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "#     after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Forward pass for before and after images\n",
    "#         before_output = model(before_image)\n",
    "#         after_output = model(after_image)\n",
    "        \n",
    "#         # Apply sigmoid and squeeze batch dimension\n",
    "#         before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "#         after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "#         # Thresholding to create binary masks\n",
    "#         before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "#         after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "#         # Calculate IOU\n",
    "#         iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "#         print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "#         # Visualize before and after masks\n",
    "#         fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "#         ax[0].imshow(before_mask, cmap='gray')\n",
    "#         ax[0].set_title(\"Before Mask\")\n",
    "#         ax[1].imshow(after_mask, cmap='gray')\n",
    "#         ax[1].set_title(\"After Mask\")\n",
    "#         ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "#         ax[2].set_title(\"Change Mask\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "# def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "#     before_image = Image.open(before_image_path)\n",
    "#     after_image = Image.open(after_image_path)\n",
    "\n",
    "#     # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "#     before_image = before_image.convert('RGB')\n",
    "#     after_image = after_image.convert('RGB')\n",
    "\n",
    "#     # Preprocessing and transforming images to tensor\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "#     after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Forward pass for before and after images\n",
    "#         before_output = model(before_image)\n",
    "#         after_output = model(after_image)\n",
    "        \n",
    "#         # Apply sigmoid and squeeze batch dimension\n",
    "#         before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "#         after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "#         # Thresholding to create binary masks\n",
    "#         before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "#         after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "#         # Calculate IOU\n",
    "#         iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "#         print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "#         # Visualize before and after masks\n",
    "#         fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "#         ax[0].imshow(before_mask, cmap='gray')\n",
    "#         ax[0].set_title(\"Before Mask\")\n",
    "#         ax[1].imshow(after_mask, cmap='gray')\n",
    "#         ax[1].set_title(\"After Mask\")\n",
    "#         ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "#         ax[2].set_title(\"Change Mask\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "# def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "#     before_image = Image.open(before_image_path)\n",
    "#     after_image = Image.open(after_image_path)\n",
    "\n",
    "#     # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "#     before_image = before_image.convert('RGB')\n",
    "#     after_image = after_image.convert('RGB')\n",
    "\n",
    "#     # Preprocessing and transforming images to tensor\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "#     after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Forward pass for before and after images\n",
    "#         before_output = model(before_image)\n",
    "#         after_output = model(after_image)\n",
    "        \n",
    "#         # Apply sigmoid and squeeze batch dimension\n",
    "#         before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "#         after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "#         # Ensure that before_mask and after_mask are 2D (height, width)\n",
    "#         if before_mask.ndim == 3:\n",
    "#             before_mask = before_mask[0]  # If there's an extra channel dimension\n",
    "#         if after_mask.ndim == 3:\n",
    "#             after_mask = after_mask[0]  # If there's an extra channel dimension\n",
    "\n",
    "#         # Thresholding to create binary masks\n",
    "#         before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "#         after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "#         # Calculate IOU\n",
    "#         iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "#         print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "#         # Visualize before and after masks\n",
    "#         fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "#         ax[0].imshow(before_mask, cmap='gray')\n",
    "#         ax[0].set_title(\"Before Mask\")\n",
    "#         ax[1].imshow(after_mask, cmap='gray')\n",
    "#         ax[1].set_title(\"After Mask\")\n",
    "#         ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "#         ax[2].set_title(\"Change Mask\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "#     before_image = Image.open(before_image_path)\n",
    "#     after_image = Image.open(after_image_path)\n",
    "\n",
    "#     # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "#     before_image = before_image.convert('RGB')\n",
    "#     after_image = after_image.convert('RGB')\n",
    "\n",
    "#     # Preprocessing and transforming images to tensor\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "#     after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Forward pass for before and after images\n",
    "#         before_output = model(before_image)\n",
    "#         after_output = model(after_image)\n",
    "        \n",
    "#         # Apply sigmoid and squeeze batch dimension\n",
    "#         before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "#         after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "#         # Ensure both masks are binary\n",
    "#         before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "#         after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "#         # Resize after_mask to match before_mask shape\n",
    "#         if before_mask.shape != after_mask.shape:\n",
    "#             after_mask = cv2.resize(after_mask, (before_mask.shape[1], before_mask.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "#         # Calculate IOU\n",
    "#         iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "#         print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "#         # Visualize before and after masks\n",
    "#         fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "#         ax[0].imshow(before_mask, cmap='gray')\n",
    "#         ax[0].set_title(\"Before Mask\")\n",
    "#         ax[1].imshow(after_mask, cmap='gray')\n",
    "#         ax[1].set_title(\"After Mask\")\n",
    "#         ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "#         ax[2].set_title(\"Change Mask\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "#     before_image = Image.open(before_image_path)\n",
    "#     after_image = Image.open(after_image_path)\n",
    "\n",
    "#     # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "#     before_image = before_image.convert('RGB')\n",
    "#     after_image = after_image.convert('RGB')\n",
    "\n",
    "#     # Preprocessing and transforming images to tensor\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "#     after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Forward pass for before and after images\n",
    "#         before_output = model(before_image)\n",
    "#         after_output = model(after_image)\n",
    "        \n",
    "#         # Apply sigmoid and squeeze batch dimension\n",
    "#         before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "#         after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "#         # Ensure both masks are binary\n",
    "#         before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "#         after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "#         # Check and print shapes of the masks\n",
    "#         print(\"Before Mask Shape:\", before_mask.shape)\n",
    "#         print(\"After Mask Shape:\", after_mask.shape)\n",
    "\n",
    "#         # Ensure both masks have valid shapes before attempting resize\n",
    "#         if before_mask.shape != after_mask.shape:\n",
    "#             target_shape = (before_mask.shape[1], before_mask.shape[0])\n",
    "#             if target_shape[0] > 0 and target_shape[1] > 0:\n",
    "#                 print(f\"Resizing after_mask to: {target_shape}\")\n",
    "#                 after_mask = cv2.resize(after_mask, target_shape, interpolation=cv2.INTER_LINEAR)\n",
    "#             else:\n",
    "#                 print(\"Invalid target shape. Skipping resize.\")\n",
    "#                 return  # Exit function if invalid target shape\n",
    "\n",
    "#         # Calculate IOU\n",
    "#         iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "#         print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "#         # Visualize before and after masks\n",
    "#         fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "#         ax[0].imshow(before_mask, cmap='gray')\n",
    "#         ax[0].set_title(\"Before Mask\")\n",
    "#         ax[1].imshow(after_mask, cmap='gray')\n",
    "#         ax[1].set_title(\"After Mask\")\n",
    "#         ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "#         ax[2].set_title(\"Change Mask\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "#     before_image = Image.open(before_image_path)\n",
    "#     after_image = Image.open(after_image_path)\n",
    "\n",
    "#     # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "#     before_image = before_image.convert('RGB')\n",
    "#     after_image = after_image.convert('RGB')\n",
    "\n",
    "#     # Preprocessing and transforming images to tensor\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "#     after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Forward pass for before and after images\n",
    "#         before_output = model(before_image)\n",
    "#         after_output = model(after_image)\n",
    "        \n",
    "#         # Apply sigmoid and squeeze batch dimension\n",
    "#         before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "#         after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "#         # Thresholding to create binary masks\n",
    "#         before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "#         after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "#         # Ensure both masks are the same shape\n",
    "#         if before_mask.shape != after_mask.shape:\n",
    "#             print(f\"Before Mask Shape: {before_mask.shape}\")\n",
    "#             print(f\"After Mask Shape: {after_mask.shape}\")\n",
    "#             # Resize after_mask to match before_mask shape\n",
    "#             after_mask = cv2.resize(after_mask, (before_mask.shape[1], before_mask.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "#             print(f\"Resized After Mask Shape: {after_mask.shape}\")\n",
    "\n",
    "#         # Calculate IOU\n",
    "#         iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "#         print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "#         # Visualize before and after masks\n",
    "#         fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "#         ax[0].imshow(before_mask, cmap='gray')\n",
    "#         ax[0].set_title(\"Before Mask\")\n",
    "#         ax[1].imshow(after_mask, cmap='gray')\n",
    "#         ax[1].set_title(\"After Mask\")\n",
    "#         ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "#         ax[2].set_title(\"Change Mask\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "# def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "#     before_image = Image.open(before_image_path)\n",
    "#     after_image = Image.open(after_image_path)\n",
    "\n",
    "#     # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "#     before_image = before_image.convert('RGB')\n",
    "#     after_image = after_image.convert('RGB')\n",
    "\n",
    "#     # Preprocessing and transforming images to tensor\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "#     after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Forward pass for before and after images\n",
    "#         before_output = model(before_image)\n",
    "#         after_output = model(after_image)\n",
    "        \n",
    "#         # Apply sigmoid and squeeze batch dimension\n",
    "#         before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "#         after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "#         # Thresholding to create binary masks\n",
    "#         before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "#         after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "#         # Print out shapes for debugging\n",
    "#         print(f\"Before Mask Shape: {before_mask.shape}\")\n",
    "#         print(f\"After Mask Shape: {after_mask.shape}\")\n",
    "\n",
    "#         # Ensure both masks are the same shape\n",
    "#         if before_mask.shape != after_mask.shape:\n",
    "#             print(f\"Resizing needed, Before Mask: {before_mask.shape}, After Mask: {after_mask.shape}\")\n",
    "            \n",
    "#             # Check if after_mask is not empty and before resizing\n",
    "#             if after_mask.shape[0] > 0 and after_mask.shape[1] > 0:\n",
    "#                 try:\n",
    "#                     # Resize after_mask to match before_mask shape\n",
    "#                     after_mask = cv2.resize(after_mask, (before_mask.shape[1], before_mask.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "#                     print(f\"Resized After Mask Shape: {after_mask.shape}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error resizing after_mask: {e}\")\n",
    "#             else:\n",
    "#                 print(\"After mask has an invalid shape. Cannot resize.\")\n",
    "        \n",
    "#         # Ensure the final masks are not empty\n",
    "#         if before_mask.shape[0] == 0 or before_mask.shape[1] == 0:\n",
    "#             print(\"Error: Before mask has invalid shape.\")\n",
    "#             return\n",
    "#         if after_mask.shape[0] == 0 or after_mask.shape[1] == 0:\n",
    "#             print(\"Error: After mask has invalid shape.\")\n",
    "#             return\n",
    "\n",
    "#         # Calculate IOU\n",
    "#         iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "#         print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "#         # Visualize before and after masks\n",
    "#         fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "#         ax[0].imshow(before_mask, cmap='gray')\n",
    "#         ax[0].set_title(\"Before Mask\")\n",
    "#         ax[1].imshow(after_mask, cmap='gray')\n",
    "#         ax[1].set_title(\"After Mask\")\n",
    "#         ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "#         ax[2].set_title(\"Change Mask\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "# def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "#     before_image = Image.open(before_image_path)\n",
    "#     after_image = Image.open(after_image_path)\n",
    "\n",
    "#     # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "#     before_image = before_image.convert('RGB')\n",
    "#     after_image = after_image.convert('RGB')\n",
    "\n",
    "#     # Preprocessing and transforming images to tensor\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "#     after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Forward pass for before and after images\n",
    "#         before_output = model(before_image)\n",
    "#         after_output = model(after_image)\n",
    "        \n",
    "#         # Apply sigmoid and squeeze batch dimension\n",
    "#         before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "#         after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "#         # Thresholding to create binary masks\n",
    "#         before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "#         after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "#         # Print out shapes for debugging\n",
    "#         print(f\"Before Mask Shape: {before_mask.shape}\")\n",
    "#         print(f\"After Mask Shape: {after_mask.shape}\")\n",
    "\n",
    "#         # Resize both masks to the same shape (use before_mask shape as target)\n",
    "#         if before_mask.shape != after_mask.shape:\n",
    "#             print(f\"Resizing both masks to match the shape of the before_mask: {before_mask.shape}\")\n",
    "            \n",
    "#             # Resize after_mask to match before_mask shape\n",
    "#             after_mask = cv2.resize(after_mask, (before_mask.shape[1], before_mask.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "#             print(f\"Resized After Mask Shape: {after_mask.shape}\")\n",
    "        \n",
    "#         # Ensure the final masks are not empty\n",
    "#         if before_mask.shape[0] == 0 or before_mask.shape[1] == 0:\n",
    "#             print(\"Error: Before mask has invalid shape.\")\n",
    "#             return\n",
    "#         if after_mask.shape[0] == 0 or after_mask.shape[1] == 0:\n",
    "#             print(\"Error: After mask has invalid shape.\")\n",
    "#             return\n",
    "\n",
    "#         # Calculate IOU\n",
    "#         iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "#         print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "#         # Visualize before and after masks\n",
    "#         fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "#         ax[0].imshow(before_mask, cmap='gray')\n",
    "#         ax[0].set_title(\"Before Mask\")\n",
    "#         ax[1].imshow(after_mask, cmap='gray')\n",
    "#         ax[1].set_title(\"After Mask\")\n",
    "#         ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "#         ax[2].set_title(\"Change Mask\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "#     before_image = Image.open(before_image_path)\n",
    "#     after_image = Image.open(after_image_path)\n",
    "\n",
    "#     # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "#     before_image = before_image.convert('RGB')\n",
    "#     after_image = after_image.convert('RGB')\n",
    "\n",
    "#     # Preprocessing and transforming images to tensor\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "\n",
    "#     before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "#     after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         # Forward pass for before and after images\n",
    "#         before_output = model(before_image)\n",
    "#         after_output = model(after_image)\n",
    "        \n",
    "#         # Apply sigmoid and squeeze batch dimension\n",
    "#         before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "#         after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "#         # Thresholding to create binary masks\n",
    "#         before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "#         after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "#         # Print out shapes for debugging\n",
    "#         print(f\"Before Mask Shape: {before_mask.shape}\")\n",
    "#         print(f\"After Mask Shape: {after_mask.shape}\")\n",
    "\n",
    "#         # Check if both masks are non-zero in shape\n",
    "#         if before_mask.shape[0] == 0 or before_mask.shape[1] == 0:\n",
    "#             print(\"Error: Before mask has invalid shape.\")\n",
    "#             return\n",
    "#         if after_mask.shape[0] == 0 or after_mask.shape[1] == 0:\n",
    "#             print(\"Error: After mask has invalid shape.\")\n",
    "#             return\n",
    "\n",
    "#         # Resize both masks to the same shape (use before_mask shape as target)\n",
    "#         if before_mask.shape != after_mask.shape:\n",
    "#             print(f\"Resizing both masks to match the shape of the before_mask: {before_mask.shape}\")\n",
    "            \n",
    "#             # Resize after_mask to match before_mask shape\n",
    "#             try:\n",
    "#                 after_mask = cv2.resize(after_mask, (before_mask.shape[1], before_mask.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "#                 print(f\"Resized After Mask Shape: {after_mask.shape}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error resizing after_mask: {e}\")\n",
    "#                 return\n",
    "        \n",
    "#         # Calculate IOU\n",
    "#         iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "#         print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "#         # Visualize before and after masks\n",
    "#         fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "#         ax[0].imshow(before_mask, cmap='gray')\n",
    "#         ax[0].set_title(\"Before Mask\")\n",
    "#         ax[1].imshow(after_mask, cmap='gray')\n",
    "#         ax[1].set_title(\"After Mask\")\n",
    "#         ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "#         ax[2].set_title(\"Change Mask\")\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "def visualize_and_calculate(before_image_path, after_image_path, model, device):\n",
    "    before_image = Image.open(before_image_path)\n",
    "    after_image = Image.open(after_image_path)\n",
    "\n",
    "    # Convert images to RGB (in case they are in RGBA or another mode)\n",
    "    before_image = before_image.convert('RGB')\n",
    "    after_image = after_image.convert('RGB')\n",
    "\n",
    "    # Preprocessing and transforming images to tensor\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    before_image = transform(before_image).unsqueeze(0).to(device)\n",
    "    after_image = transform(after_image).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass for before and after images\n",
    "        before_output = model(before_image)\n",
    "        after_output = model(after_image)\n",
    "        \n",
    "        # Apply sigmoid and squeeze batch dimension\n",
    "        before_mask = torch.sigmoid(before_output).squeeze(0).cpu().numpy()\n",
    "        after_mask = torch.sigmoid(after_output).squeeze(0).cpu().numpy()\n",
    "\n",
    "        # Thresholding to create binary masks\n",
    "        before_mask = (before_mask > 0.5).astype(np.uint8)\n",
    "        after_mask = (after_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "        # Print out shapes for debugging\n",
    "        print(f\"Before Mask Shape: {before_mask.shape}\")\n",
    "        print(f\"After Mask Shape: {after_mask.shape}\")\n",
    "\n",
    "        # Ensure masks are non-empty and valid before resizing\n",
    "        if before_mask.shape[0] == 0 or before_mask.shape[1] == 0:\n",
    "            print(\"Error: Before mask has invalid shape.\")\n",
    "            return\n",
    "        if after_mask.shape[0] == 0 or after_mask.shape[1] == 0:\n",
    "            print(\"Error: After mask has invalid shape.\")\n",
    "            return\n",
    "\n",
    "        # If shapes differ, resize them to the same shape\n",
    "        if before_mask.shape != after_mask.shape:\n",
    "            print(f\"Resizing both masks to match the shape of the before_mask: {before_mask.shape}\")\n",
    "            \n",
    "            # Ensure after_mask has valid shape for resizing\n",
    "            if after_mask.shape[0] > 0 and after_mask.shape[1] > 0:\n",
    "                try:\n",
    "                    after_mask_resized = cv2.resize(after_mask, (before_mask.shape[1], before_mask.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "                    print(f\"Resized After Mask Shape: {after_mask_resized.shape}\")\n",
    "                    after_mask = after_mask_resized  # Use resized mask\n",
    "                except Exception as e:\n",
    "                    print(f\"Error resizing after_mask: {e}\")\n",
    "                    return\n",
    "            else:\n",
    "                print(\"Error: Invalid after_mask dimensions for resizing.\")\n",
    "                return\n",
    "        \n",
    "        # Calculate IOU\n",
    "        iou_before_after = calculate_iou(before_mask, after_mask)\n",
    "        print(f\"IoU between Before and After Masks: {iou_before_after:.4f}\")\n",
    "\n",
    "        # Visualize before and after masks\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "        ax[0].imshow(before_mask, cmap='gray')\n",
    "        ax[0].set_title(\"Before Mask\")\n",
    "        ax[1].imshow(after_mask, cmap='gray')\n",
    "        ax[1].set_title(\"After Mask\")\n",
    "        ax[2].imshow(np.abs(before_mask - after_mask), cmap='hot')\n",
    "        ax[2].set_title(\"Change Mask\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main Script\n",
    "if __name__ == \"__main__\":\n",
    "    # Device configuration\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    # Paths to the dataset (replace with your actual paths)\n",
    "    images_dir = 'data/images'  # Your images path\n",
    "    masks_dir = 'data/masks'  # Your masks path\n",
    "    \n",
    "    # Dataset and DataLoader setup\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((400, 400)),  # Ensure images are of the same size (adjust as needed)\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    dataset = GlacierDataset(images_dir, masks_dir, transform=transform)\n",
    "    train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, device, num_epochs=1, lr=0.001)\n",
    "\n",
    "    # After training, visualize and calculate\n",
    "    before_image_path = \"before.png\"  # Example image path\n",
    "    after_image_path = \"after.png\"   # Example image path\n",
    "    visualize_and_calculate(before_image_path, after_image_path, model, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
